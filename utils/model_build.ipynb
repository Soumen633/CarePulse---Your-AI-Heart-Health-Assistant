{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62b24a7-8dc5-4339-8407-bf0ccf85fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score, f1_score, recall_score, precision_score, \n",
    "                             roc_curve, roc_auc_score, confusion_matrix, \n",
    "                             classification_report, ConfusionMatrixDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73e6d8a-d492-4e67-a4a2-5bbc022daec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping features: id\n",
      "Dropping features: age\n",
      "Dropping features: height\n",
      "\n",
      "Feature Importance (F-test):\n",
      "============================================================\n",
      "gender                             : F=   4.604, p=0.032\n",
      "weight                             : F=2702.000, p=0.000\n",
      "ap_hi                              : F=21922.892, p=0.000\n",
      "ap_lo                              : F=11575.413, p=0.000\n",
      "cholesterol                        : F=15554.452, p=0.000\n",
      "gluc                               : F= 562.773, p=0.000\n",
      "smoke                              : F=  16.791, p=0.000\n",
      "alco                               : F=   3.761, p=0.052\n",
      "active                             : F=  89.091, p=0.000\n",
      "age_years                          : F=4193.662, p=0.000\n",
      "bmi                                : F=3015.623, p=0.000\n",
      "pulse_pressure                     : F=11607.067, p=0.000\n",
      "health_index                       : F=  44.285, p=0.000\n",
      "cholesterol_gluc_interaction       : F=6925.072, p=0.000\n",
      "\n",
      "Dataset Split:\n",
      "X_train shape: (52500, 14)\n",
      "y_train shape: (52500,)\n",
      "X_test shape:  (17500, 14)\n",
      "y_test shape:  (17500,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Cardiovascular Disease Prediction Model\n",
    "Achieves 83% accuracy using Decision Tree and Random Forest models\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# LIBRARIES IMPORT\n",
    "# ============================================================================\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_curve, roc_auc_score\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET IMPORT\n",
    "# ============================================================================\n",
    "df = pd.read_csv(\"../CarePulse/new data/cardio_train.csv\", sep=\";\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "TARGET = 'cardio'\n",
    "INPUT_FEATURES = ['id', 'age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo',\n",
    "                  'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "\n",
    "CACHE_MODELS_DIR_NAME = 'models_cache'\n",
    "os.makedirs(CACHE_MODELS_DIR_NAME, exist_ok=True)\n",
    "\n",
    "plt.style.use(plt.style.available[12])\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "def drop_unwanted_features(df, features_to_drop):\n",
    "    \"\"\"Drop unwanted features from dataframe and INPUT_FEATURES list\"\"\"\n",
    "    print(f\"Dropping features: {features_to_drop}\")\n",
    "    \n",
    "    if features_to_drop in list(df.columns):\n",
    "        df = df.drop(columns=features_to_drop)\n",
    "    \n",
    "    if features_to_drop in INPUT_FEATURES:\n",
    "        INPUT_FEATURES.remove(features_to_drop)\n",
    "    return df\n",
    "\n",
    "def IQR(series):\n",
    "    \"\"\"Apply IQR method to clip outliers\"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR_val = Q3 - Q1\n",
    "    min_v = Q1 - 1.5 * IQR_val\n",
    "    max_v = Q3 + 1.5 * IQR_val\n",
    "    return series.clip(lower=min_v, upper=max_v)\n",
    "\n",
    "# ============================================================================\n",
    "# CUSTOM MODEL CLASS\n",
    "# ============================================================================\n",
    "class CustomModel:\n",
    "    def __init__(self, name, model, extra_train_param=None):\n",
    "        self.name = str(name)\n",
    "        self.model = model\n",
    "        self.extra_train_param = extra_train_param\n",
    "        self.y_train_hat = None\n",
    "        self.y_test_hat = None\n",
    "        self.feature_names = None\n",
    "        self.load()\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        if not getattr(self, \"trained\", False):\n",
    "            if self.extra_train_param is None:\n",
    "                self.model.fit(x_train, y_train)\n",
    "            else:\n",
    "                self.model.fit(x_train, y_train, **self.extra_train_param)\n",
    "            \n",
    "            self.feature_names = list(x_train.columns)\n",
    "            self.trained = True\n",
    "            self.save()\n",
    "\n",
    "    def _align_features(self, X):\n",
    "        \"\"\"Ensure X has the same columns as training data\"\"\"\n",
    "        if self.feature_names is not None:\n",
    "            missing_cols = set(self.feature_names) - set(X.columns)\n",
    "            extra_cols = set(X.columns) - set(self.feature_names)\n",
    "            \n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns in input: {missing_cols}\")\n",
    "            if extra_cols:\n",
    "                X = X[self.feature_names]\n",
    "            else:\n",
    "                X = X[self.feature_names]\n",
    "        return X\n",
    "\n",
    "    def predict_on_train(self, x_train):\n",
    "        if self.y_train_hat is None:\n",
    "            x_train = self._align_features(x_train)\n",
    "            self.y_train_hat = self.model.predict(x_train)\n",
    "\n",
    "    def predict_on_test(self, x_test):\n",
    "        if self.y_test_hat is None:\n",
    "            x_test = self._align_features(x_test)\n",
    "            self.y_test_hat = self.model.predict(x_test)\n",
    "\n",
    "    def save(self):\n",
    "        file_name = re.sub(r'\\W+', '_', str(self.name).lower())\n",
    "        file_path = CACHE_MODELS_DIR_NAME + '/' + file_name + '.pickle'\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                \"model\": self.model,\n",
    "                \"trained\": self.trained,\n",
    "                \"feature_names\": self.feature_names\n",
    "            }, f)\n",
    "\n",
    "    def load(self):\n",
    "        file_name = re.sub(r'\\W+', '_', str(self.name).lower())\n",
    "        file_path = CACHE_MODELS_DIR_NAME + '/' + file_name + '.pickle'\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                self.model = data[\"model\"]\n",
    "                self.trained = data[\"trained\"]\n",
    "                self.feature_names = data.get(\"feature_names\", None)\n",
    "        else:\n",
    "            self.trained = False\n",
    "\n",
    "# ============================================================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "# Drop ID column\n",
    "df = drop_unwanted_features(df, 'id')\n",
    "\n",
    "# Handle outliers using IQR method\n",
    "exclude = ['gluc', 'alco', 'smoke', 'colesterol', 'active']\n",
    "for num_feature in [f for f in INPUT_FEATURES if f not in exclude]:\n",
    "    for gender_category in df[TARGET].unique():\n",
    "        mask = df[TARGET] == gender_category\n",
    "        df.loc[mask, num_feature] = IQR(df.loc[mask, num_feature])\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "# Convert age from days to years\n",
    "df['age_years'] = (df['age'] / 365).round().astype(int)\n",
    "\n",
    "# Convert height from cm to meters\n",
    "df['height'] = df['height'] / 100\n",
    "\n",
    "# Calculate BMI\n",
    "df['bmi'] = df['weight'] / ((df['height'] / 100) ** 2)\n",
    "\n",
    "# Calculate pulse pressure\n",
    "df['pulse_pressure'] = df['ap_hi'] - df['ap_lo']\n",
    "\n",
    "# Create health index\n",
    "df['health_index'] = (df['active'] * 1) - (df['smoke'] * 0.5) - (df['alco'] * 0.5)\n",
    "\n",
    "# Create interaction feature\n",
    "df['cholesterol_gluc_interaction'] = df['cholesterol'] * df['gluc']\n",
    "\n",
    "# Update input features list\n",
    "new_features = [\n",
    "    'age_years',\n",
    "    'bmi',\n",
    "    'pulse_pressure',\n",
    "    'health_index',\n",
    "    'cholesterol_gluc_interaction'\n",
    "]\n",
    "INPUT_FEATURES = INPUT_FEATURES + [f for f in new_features if f not in INPUT_FEATURES]\n",
    "\n",
    "# Drop original age and height columns\n",
    "df = drop_unwanted_features(df, 'age')\n",
    "df = drop_unwanted_features(df, 'height')\n",
    "\n",
    "# Final feature list\n",
    "INPUT_FEATURES = ['gender', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', \n",
    "                  'smoke', 'alco', 'active', 'age_years', 'bmi', 'pulse_pressure',\n",
    "                  'health_index', 'cholesterol_gluc_interaction']\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE SELECTION (F-test)\n",
    "# ============================================================================\n",
    "f_values, p_values = f_classif(df[INPUT_FEATURES], df[TARGET])\n",
    "\n",
    "print(\"\\nFeature Importance (F-test):\")\n",
    "print(\"=\" * 60)\n",
    "for i in range(len(INPUT_FEATURES)):\n",
    "    print(f\"{INPUT_FEATURES[i]:35s}: F={f_values[i]:8.3f}, p={p_values[i]:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN-TEST SPLIT\n",
    "# ============================================================================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(TARGET, axis=1),\n",
    "    df.loc[:, TARGET],\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=df.loc[:, TARGET],\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset Split:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape:  {X_test.shape}\")\n",
    "print(f\"y_test shape:  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11117e41-4aa8-418f-bba1-5c20c9eae861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization directory\n",
    "VIZ_DIR = 'visualizations'\n",
    "os.makedirs(VIZ_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0e71d5-a783-4bc6-8789-68c59a626694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4] GENERATING VISUALIZATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ Saved: Correlation Matrix\n",
      "âœ“ Saved: Feature Distributions\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 1: CORRELATION MATRIX\n",
    "# ============================================================================\n",
    "print(\"\\n[4] GENERATING VISUALIZATIONS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix = df[INPUT_FEATURES + [TARGET]].corr()\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', \n",
    "            cmap='coolwarm', center=0, square=True, linewidths=1,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/01_correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: Correlation Matrix\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 2: FEATURE DISTRIBUTIONS\n",
    "# ============================================================================\n",
    "fig, axes = plt.subplots(4, 4, figsize=(16, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, feature in enumerate(INPUT_FEATURES):\n",
    "    if idx < len(axes):\n",
    "        for target_val in [0, 1]:\n",
    "            data = df[df[TARGET] == target_val][feature]\n",
    "            axes[idx].hist(data, alpha=0.6, bins=30, \n",
    "                          label=f'Cardio={target_val}', density=True)\n",
    "        axes[idx].set_title(feature, fontweight='bold')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Target Class', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/02_feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: Feature Distributions\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77eed167-7357-4775-9960-86851e8f78ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5] TRAINING BASELINE MODELS (Before Hyperparameter Tuning)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Training Decision Tree...\n",
      "  Accuracy:  0.7788\n",
      "  F1 Score:  0.7765\n",
      "  Precision: 0.7841\n",
      "  Recall:    0.7691\n",
      "\n",
      "Training Random Forest...\n",
      "  Accuracy:  0.8098\n",
      "  F1 Score:  0.7975\n",
      "  Precision: 0.8519\n",
      "  Recall:    0.7497\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  Accuracy:  0.8306\n",
      "  F1 Score:  0.8052\n",
      "  Precision: 0.9465\n",
      "  Recall:    0.7005\n",
      "\n",
      "Training XGBoost...\n",
      "  Accuracy:  0.8310\n",
      "  F1 Score:  0.8119\n",
      "  Precision: 0.9144\n",
      "  Recall:    0.7301\n",
      "\n",
      "Training CatBoost...\n",
      "  Accuracy:  0.8311\n",
      "  F1 Score:  0.8115\n",
      "  Precision: 0.9176\n",
      "  Recall:    0.7274\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL TRAINING - BASELINE MODELS (Before Tuning)\n",
    "# ============================================================================\n",
    "print(\"\\n[5] TRAINING BASELINE MODELS (Before Hyperparameter Tuning)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "baseline_models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=105, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss'),\n",
    "    'CatBoost': CatBoostClassifier(iterations=100, random_state=42, verbose=0)\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    baseline_results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c253471-de45-4746-bd53-3a88450d1b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================================\n",
    "# # HYPERPARAMETER TUNING\n",
    "# # ============================================================================\n",
    "# print(\"\\n[6] HYPERPARAMETER TUNING\")\n",
    "# print(\"-\" * 80)\n",
    "\n",
    "# # Decision Tree Parameters\n",
    "# dt_param_grid = {\n",
    "#     'max_depth': [5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "\n",
    "# # Random Forest Parameters\n",
    "# rf_param_grid = {\n",
    "#     'bootstrap': True,\n",
    "#   'criterion': 'entropy',\n",
    "#   'max_depth': 25,\n",
    "#   'max_features': 0.4,\n",
    "#   'min_impurity_decrease': 0.0,\n",
    "#   'min_samples_leaf': 4,\n",
    "#   'min_samples_split': 12,\n",
    "#   'n_estimators': 100\n",
    "# }\n",
    "\n",
    "# # Gradient Boosting Parameters\n",
    "# gb_param_grid = {\n",
    "#     'n_estimators': [100, 150, 200],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'min_samples_split': [2, 5],\n",
    "#     'subsample': [0.8, 0.9, 1.0]\n",
    "# }\n",
    "\n",
    "# # XGBoost Parameters\n",
    "# xgb_param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'subsample': [0.8, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "# }\n",
    "\n",
    "# # CatBoost Parameters\n",
    "# catboost_param_grid = {\n",
    "#     'iterations': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'depth': [4, 6, 8],\n",
    "#     'l2_leaf_reg': [1, 3, 5]\n",
    "# }\n",
    "\n",
    "# tuned_models = {}\n",
    "# param_grids = {\n",
    "#     'Decision Tree': dt_param_grid,\n",
    "#     'Random Forest': rf_param_grid,\n",
    "#     'Gradient Boosting': gb_param_grid,\n",
    "#     'XGBoost': xgb_param_grid,\n",
    "#     'CatBoost': catboost_param_grid\n",
    "# }\n",
    "\n",
    "# for name, model in baseline_models.items():\n",
    "#     print(f\"\\nTuning {name}...\")\n",
    "    \n",
    "#     if name in ['Random Forest', 'XGBoost']:\n",
    "#         # Use RandomizedSearchCV for larger parameter spaces\n",
    "#         search = RandomizedSearchCV(\n",
    "#             model, param_grids[name], n_iter=20, cv=3, \n",
    "#             scoring='f1', random_state=42, n_jobs=-1, verbose=0\n",
    "#         )\n",
    "#     else:\n",
    "#         # Use GridSearchCV for smaller parameter spaces\n",
    "#         search = GridSearchCV(\n",
    "#             model, param_grids[name], cv=3, \n",
    "#             scoring='f1', n_jobs=-1, verbose=0\n",
    "#         )\n",
    "    \n",
    "#     search.fit(X_train, y_train)\n",
    "    \n",
    "#     best_model = search.best_estimator_\n",
    "#     y_pred = best_model.predict(X_test)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     f1 = f1_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred)\n",
    "#     recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "#     tuned_models[name] = {\n",
    "#         'model': best_model,\n",
    "#         'accuracy': accuracy,\n",
    "#         'f1_score': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall,\n",
    "#         'y_pred': y_pred,\n",
    "#         'best_params': search.best_params_\n",
    "#     }\n",
    "    \n",
    "#     print(f\"  Best Parameters: {search.best_params_}\")\n",
    "#     print(f\"  Accuracy:  {accuracy:.4f} (Î” {accuracy - baseline_results[name]['accuracy']:+.4f})\")\n",
    "#     print(f\"  F1 Score:  {f1:.4f} (Î” {f1 - baseline_results[name]['f1_score']:+.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84dbe71c-d3c3-49aa-ae6f-7cea67321804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] HYPERPARAMETER TUNING\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Tuning Decision Tree...\n",
      "  Best Parameters: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 2}\n",
      "  Accuracy: 0.8273 (Î” +0.0485)\n",
      "  F1 Score: 0.8054 (Î” +0.0289)\n",
      "\n",
      "Tuning Random Forest...\n",
      "  Best Parameters: (pre-tuned & fixed)\n",
      "  Accuracy: 0.8299 (Î” +0.0201)\n",
      "  F1 Score: 0.8103 (Î” +0.0128)\n",
      "\n",
      "Tuning Gradient Boosting...\n",
      "  Best Parameters: {'learning_rate': 0.05, 'max_depth': 7, 'min_samples_split': 5, 'n_estimators': 150, 'subsample': 0.9}\n",
      "  Accuracy: 0.8332 (Î” +0.0026)\n",
      "  F1 Score: 0.8121 (Î” +0.0069)\n",
      "\n",
      "Tuning XGBoost...\n",
      "  Best Parameters: {'subsample': 0.9, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "  Accuracy: 0.8335 (Î” +0.0026)\n",
      "  F1 Score: 0.8141 (Î” +0.0022)\n",
      "\n",
      "Tuning CatBoost...\n",
      "  Best Parameters: {'depth': 4, 'iterations': 300, 'l2_leaf_reg': 1, 'learning_rate': 0.1}\n",
      "  Accuracy: 0.8326 (Î” +0.0014)\n",
      "  F1 Score: 0.8115 (Î” -0.0000)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETER TUNING + INTEGRATION OF PRE-TUNED RANDOM FOREST\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"\\n[6] HYPERPARAMETER TUNING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# --------------------------\n",
    "# PARAMETER GRIDS\n",
    "# --------------------------\n",
    "\n",
    "dt_param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "catboost_param_grid = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'depth': [4, 6, 8],\n",
    "    'l2_leaf_reg': [1, 3, 5]\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'Decision Tree': dt_param_grid,\n",
    "    'Gradient Boosting': gb_param_grid,\n",
    "    'XGBoost': xgb_param_grid,\n",
    "    'CatBoost': catboost_param_grid\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# PRE-TUNED RANDOM FOREST PARAMS\n",
    "# --------------------------\n",
    "\n",
    "rf_best_params = {\n",
    "    'bootstrap': True,\n",
    "    'criterion': 'entropy',\n",
    "    'max_depth': 25,\n",
    "    'max_features': 0.4,\n",
    "    'min_impurity_decrease': 0.0,\n",
    "    'min_samples_leaf': 4,\n",
    "    'min_samples_split': 12,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# TUNING LOOP\n",
    "# --------------------------\n",
    "\n",
    "tuned_models = {}\n",
    "\n",
    "for name, model in baseline_models.items():\n",
    "    print(f\"\\nTuning {name}...\")\n",
    "\n",
    "    # ===== RANDOM FOREST (ALREADY TUNED) =====\n",
    "    if name == 'Random Forest':\n",
    "\n",
    "        best_model = RandomForestClassifier(\n",
    "            **rf_best_params,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        tuned_models[name] = {\n",
    "            'model': best_model,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred),\n",
    "            'precision': precision_score(y_test, y_pred),\n",
    "            'recall': recall_score(y_test, y_pred),\n",
    "            'y_pred': y_pred,\n",
    "            'best_params': rf_best_params\n",
    "        }\n",
    "\n",
    "        print(\"  Best Parameters: (pre-tuned & fixed)\")\n",
    "        print(f\"  Accuracy: {tuned_models[name]['accuracy']:.4f} \"\n",
    "              f\"(Î” {tuned_models[name]['accuracy'] - baseline_results[name]['accuracy']:+.4f})\")\n",
    "        print(f\"  F1 Score: {tuned_models[name]['f1_score']:.4f} \"\n",
    "              f\"(Î” {tuned_models[name]['f1_score'] - baseline_results[name]['f1_score']:+.4f})\")\n",
    "\n",
    "        continue\n",
    "\n",
    "    # ===== OTHER MODELS (SEARCH REQUIRED) =====\n",
    "\n",
    "    if name == 'XGBoost':\n",
    "        search = RandomizedSearchCV(\n",
    "            model,\n",
    "            param_grids[name],\n",
    "            n_iter=20,\n",
    "            cv=3,\n",
    "            scoring='f1',\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "    else:\n",
    "        search = GridSearchCV(\n",
    "            model,\n",
    "            param_grids[name],\n",
    "            cv=3,\n",
    "            scoring='f1',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    best_model = search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    tuned_models[name] = {\n",
    "        'model': best_model,\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'y_pred': y_pred,\n",
    "        'best_params': search.best_params_\n",
    "    }\n",
    "\n",
    "    print(f\"  Best Parameters: {search.best_params_}\")\n",
    "    print(f\"  Accuracy: {tuned_models[name]['accuracy']:.4f} \"\n",
    "          f\"(Î” {tuned_models[name]['accuracy'] - baseline_results[name]['accuracy']:+.4f})\")\n",
    "    print(f\"  F1 Score: {tuned_models[name]['f1_score']:.4f} \"\n",
    "          f\"(Î” {tuned_models[name]['f1_score'] - baseline_results[name]['f1_score']:+.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b51cceda-54bf-464d-9bd9-97a13c9aa93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7] GENERATING COMPARISON VISUALIZATIONS\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ Saved: Before vs After Comparison\n",
      "âœ“ Saved: Confusion Matrices (Tuned Models)\n",
      "âœ“ Saved: Feature Importance\n",
      "âœ“ Saved: ROC Curves\n",
      "âœ“ Saved: Gradient Boosting Detailed Confusion Matrix\n",
      "\n",
      "================================================================================\n",
      "FINAL RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š MODEL PERFORMANCE COMPARISON (After Tuning)\n",
      "--------------------------------------------------------------------------------\n",
      "            Model  Accuracy  F1 Score  Precision   Recall\n",
      "          XGBoost  0.833543  0.814139   0.920901 0.729560\n",
      "Gradient Boosting  0.833200  0.812053   0.929266 0.721098\n",
      "         CatBoost  0.832571  0.811479   0.927762 0.721098\n",
      "    Random Forest  0.829886  0.810346   0.914845 0.727273\n",
      "    Decision Tree  0.827257  0.805432   0.921231 0.715495\n",
      "\n",
      "ðŸ† BEST MODEL: XGBoost\n",
      "   F1 Score: 0.8141\n",
      "   Best Parameters: {'subsample': 0.9, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
      "\n",
      "================================================================================\n",
      "âœ… ANALYSIS COMPLETE!\n",
      "   All visualizations saved in 'visualizations/' directory\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¾ Best model saved: XGBoost\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION 3: BEFORE vs AFTER COMPARISON\n",
    "# ============================================================================\n",
    "print(\"\\n[7] GENERATING COMPARISON VISUALIZATIONS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "comparison_data = []\n",
    "for name in baseline_models.keys():\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Metric': 'Accuracy',\n",
    "        'Before': baseline_results[name]['accuracy'],\n",
    "        'After': tuned_models[name]['accuracy']\n",
    "    })\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Metric': 'F1 Score',\n",
    "        'Before': baseline_results[name]['f1_score'],\n",
    "        'After': tuned_models[name]['f1_score']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy Comparison\n",
    "accuracy_df = comparison_df[comparison_df['Metric'] == 'Accuracy']\n",
    "x = np.arange(len(baseline_models))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, accuracy_df['Before'], width, label='Before Tuning', alpha=0.8)\n",
    "ax1.bar(x + width/2, accuracy_df['After'], width, label='After Tuning', alpha=0.8)\n",
    "ax1.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Accuracy: Before vs After Hyperparameter Tuning', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(baseline_models.keys(), rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim([0.7, 0.85])\n",
    "\n",
    "# F1 Score Comparison\n",
    "f1_df = comparison_df[comparison_df['Metric'] == 'F1 Score']\n",
    "ax2.bar(x - width/2, f1_df['Before'], width, label='Before Tuning', alpha=0.8)\n",
    "ax2.bar(x + width/2, f1_df['After'], width, label='After Tuning', alpha=0.8)\n",
    "ax2.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('F1 Score: Before vs After Hyperparameter Tuning', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(baseline_models.keys(), rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "ax2.set_ylim([0.7, 0.85])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/03_before_after_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: Before vs After Comparison\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 4: CONFUSION MATRICES FOR ALL MODELS (AFTER TUNING)\n",
    "# ============================================================================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (name, results) in enumerate(tuned_models.items()):\n",
    "    cm = confusion_matrix(y_test, results['y_pred'])\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Disease', 'Disease'])\n",
    "    disp.plot(ax=axes[idx], cmap='Blues', values_format='d')\n",
    "    axes[idx].set_title(f'{name}\\nAccuracy: {results[\"accuracy\"]:.4f} | F1: {results[\"f1_score\"]:.4f}', \n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].grid(False)\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.suptitle('Confusion Matrices - Tuned Models', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/04_confusion_matrices_tuned.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: Confusion Matrices (Tuned Models)\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 5: FEATURE IMPORTANCE (TOP MODELS)\n",
    "# ============================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "models_with_importance = ['Decision Tree', 'Random Forest', 'Gradient Boosting', 'XGBoost']\n",
    "\n",
    "for idx, name in enumerate(models_with_importance):\n",
    "    model = tuned_models[name]['model']\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1][:10]  # Top 10 features\n",
    "        \n",
    "        axes[idx].barh(range(len(indices)), importances[indices], alpha=0.8)\n",
    "        axes[idx].set_yticks(range(len(indices)))\n",
    "        axes[idx].set_yticklabels([INPUT_FEATURES[i] for i in indices])\n",
    "        axes[idx].set_xlabel('Importance', fontweight='bold')\n",
    "        axes[idx].set_title(f'{name} - Top 10 Features', fontsize=12, fontweight='bold')\n",
    "        axes[idx].grid(axis='x', alpha=0.3)\n",
    "        axes[idx].invert_yaxis()\n",
    "\n",
    "plt.suptitle('Feature Importance Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/05_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: Feature Importance\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 6: ROC CURVES\n",
    "# ============================================================================\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, results in tuned_models.items():\n",
    "    model = results['model']\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f'{name} (AUC = {auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
    "plt.title('ROC Curves - Tuned Models', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc=\"lower right\", fontsize=10)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/06_roc_curves.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: ROC Curves\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 7: DETAILED CONFUSION MATRIX FOR GRADIENT BOOSTING\n",
    "# ============================================================================\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "gb_results = tuned_models['Gradient Boosting']\n",
    "cm = confusion_matrix(y_test, gb_results['y_pred'])\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
    "            xticklabels=['No Disease', 'Disease'],\n",
    "            yticklabels=['No Disease', 'Disease'],\n",
    "            linewidths=2, linecolor='black',\n",
    "            annot_kws={'size': 16, 'weight': 'bold'})\n",
    "\n",
    "plt.title('Gradient Boosting - Detailed Confusion Matrix\\n' + \n",
    "          f'Accuracy: {gb_results[\"accuracy\"]:.4f} | F1: {gb_results[\"f1_score\"]:.4f} | ' +\n",
    "          f'Precision: {gb_results[\"precision\"]:.4f} | Recall: {gb_results[\"recall\"]:.4f}',\n",
    "          fontsize=14, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{VIZ_DIR}/07_gb_confusion_matrix_detailed.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: Gradient Boosting Detailed Confusion Matrix\")\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# FINAL RESULTS SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š MODEL PERFORMANCE COMPARISON (After Tuning)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Model': list(tuned_models.keys()),\n",
    "    'Accuracy': [tuned_models[m]['accuracy'] for m in tuned_models.keys()],\n",
    "    'F1 Score': [tuned_models[m]['f1_score'] for m in tuned_models.keys()],\n",
    "    'Precision': [tuned_models[m]['precision'] for m in tuned_models.keys()],\n",
    "    'Recall': [tuned_models[m]['recall'] for m in tuned_models.keys()]\n",
    "}).sort_values('F1 Score', ascending=False)\n",
    "\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "best_model_name = summary_df.iloc[0]['Model']\n",
    "best_model_f1 = summary_df.iloc[0]['F1 Score']\n",
    "\n",
    "print(f\"\\nðŸ† BEST MODEL: {best_model_name}\")\n",
    "print(f\"   F1 Score: {best_model_f1:.4f}\")\n",
    "print(f\"   Best Parameters: {tuned_models[best_model_name]['best_params']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ANALYSIS COMPLETE!\")\n",
    "print(f\"   All visualizations saved in '{VIZ_DIR}/' directory\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE BEST MODEL\n",
    "# ============================================================================\n",
    "best_model = tuned_models[best_model_name]['model']\n",
    "with open(f'{CACHE_MODELS_DIR_NAME}/best_model_{best_model_name.lower().replace(\" \", \"_\")}.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"\\nðŸ’¾ Best model saved: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "544c1e43-7c0a-4a2b-bf75-2f766c14600b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=25, max_features=0.4,\n",
       "                       min_samples_leaf=4, min_samples_split=12, n_jobs=-1,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;entropy&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">25</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">12</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">0.4</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=25, max_features=0.4,\n",
       "                       min_samples_leaf=4, min_samples_split=12, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_models['Random Forest']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fc412f6-6b0c-4d07-8780-cf50d02abf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING RANDOM FOREST MODEL AND METADATA\n",
      "================================================================================\n",
      "Timestamp: 20251231_170752\n",
      "Save Directory: saved_models/\n",
      "\n",
      "[1] Saving Heart Disease Model (Tuned Random Forest)...\n",
      "âœ“ Model saved: heart_disease_model_20251231_170752.pkl\n",
      "  Model Type: RandomForestClassifier\n",
      "  Number of estimators: 100\n",
      "  Max depth: 25\n",
      "  Criterion: entropy\n",
      "\n",
      "[2] Saving Feature Information...\n",
      "âœ“ Feature info saved: feature_info_20251231_170752.pkl\n",
      "  Total features: 14\n",
      "  Numerical features: 8\n",
      "  Categorical features: 6\n",
      "\n",
      "[3] Saving Label Encoders...\n",
      "âœ“ Label encoders saved: label_encoders_20251231_170752.pkl\n",
      "  Encoded variables: ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'target']\n",
      "\n",
      "[4] Saving Model Metadata...\n",
      "âœ“ Model metadata saved: model_metadata_20251231_170752.pkl\n",
      "\n",
      "================================================================================\n",
      "SAVE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "âœ… All files saved successfully in 'saved_models/' directory:\n",
      "\n",
      "1. ðŸ“¦ heart_disease_model_20251231_170752.pkl\n",
      "   - Trained Random Forest model\n",
      "   - Size: 23737.08 KB\n",
      "\n",
      "2. ðŸ“Š feature_info_20251231_170752.pkl\n",
      "   - Feature names, types, descriptions\n",
      "   - Preprocessing requirements\n",
      "   - Size: 1.73 KB\n",
      "\n",
      "3. ðŸ·ï¸  label_encoders_20251231_170752.pkl\n",
      "   - Categorical variable mappings\n",
      "   - Target variable encoding\n",
      "   - Size: 0.41 KB\n",
      "\n",
      "4. ðŸ“ model_metadata_20251231_170752.pkl\n",
      "   - Model parameters and performance\n",
      "   - Training information\n",
      "   - Usage instructions\n",
      "   - Size: 2.47 KB\n",
      "\n",
      "================================================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "Test Set Accuracy:  0.829886\n",
      "Test Set F1 Score:  0.810346\n",
      "Test Set Precision: 0.914845\n",
      "Test Set Recall:    0.727273\n",
      "\n",
      "ðŸ† Top 5 Most Important Features:\n",
      "  1. ap_hi                         : 0.3384\n",
      "  2. cholesterol                   : 0.1998\n",
      "  3. ap_lo                         : 0.1008\n",
      "  4. pulse_pressure                : 0.0952\n",
      "  5. bmi                           : 0.0655\n",
      "\n",
      "================================================================================\n",
      "âœ… MODEL SAVING COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¡ Quick Load Function (save this for later use):\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "def load_heart_disease_model(timestamp):\n",
      "    '''Load the complete model package'''\n",
      "    import pickle\n",
      "    \n",
      "    # Load all components\n",
      "    with open(f'saved_models/heart_disease_model_{timestamp}.pkl', 'rb') as f:\n",
      "        model = pickle.load(f)\n",
      "    \n",
      "    with open(f'saved_models/feature_info_{timestamp}.pkl', 'rb') as f:\n",
      "        feature_info = pickle.load(f)\n",
      "    \n",
      "    with open(f'saved_models/label_encoders_{timestamp}.pkl', 'rb') as f:\n",
      "        label_encoders = pickle.load(f)\n",
      "    \n",
      "    with open(f'saved_models/model_metadata_{timestamp}.pkl', 'rb') as f:\n",
      "        metadata = pickle.load(f)\n",
      "    \n",
      "    return {\n",
      "        'model': model,\n",
      "        'feature_info': feature_info,\n",
      "        'label_encoders': label_encoders,\n",
      "        'metadata': metadata\n",
      "    }\n",
      "\n",
      "# Usage:\n",
      "# package = load_heart_disease_model('20251231_170752')\n",
      "# model = package['model']\n",
      "# predictions = model.predict(your_data)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Save Random Forest Model and All Required Metadata\n",
    "Creates 4 pickle files: model, feature_info, label_encoders, and model_metadata\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "SAVE_DIR = 'saved_models'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Generate timestamp for file naming\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING RANDOM FOREST MODEL AND METADATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Timestamp: {timestamp}\")\n",
    "print(f\"Save Directory: {SAVE_DIR}/\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. SAVE THE TRAINED MODEL (Random Forest)\n",
    "# ============================================================================\n",
    "print(\"\\n[1] Saving Heart Disease Model (Tuned Random Forest)...\")\n",
    "\n",
    "# Extract the tuned Random Forest model from tuned_models dictionary\n",
    "best_rf_model = tuned_models['Random Forest']['model']\n",
    "\n",
    "# Save the model\n",
    "model_filename = f'heart_disease_model_{timestamp}.pkl'\n",
    "model_path = os.path.join(SAVE_DIR, model_filename)\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(best_rf_model, f)\n",
    "\n",
    "print(f\"âœ“ Model saved: {model_filename}\")\n",
    "print(f\"  Model Type: {type(best_rf_model).__name__}\")\n",
    "print(f\"  Number of estimators: {best_rf_model.n_estimators}\")\n",
    "print(f\"  Max depth: {best_rf_model.max_depth}\")\n",
    "print(f\"  Criterion: {best_rf_model.criterion}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. SAVE FEATURE INFORMATION\n",
    "# ============================================================================\n",
    "print(\"\\n[2] Saving Feature Information...\")\n",
    "\n",
    "# Create comprehensive feature information\n",
    "feature_info = {\n",
    "    'feature_names': list(X_train.columns),\n",
    "    'n_features': len(X_train.columns),\n",
    "    'feature_types': {\n",
    "        'numerical': ['age_years', 'weight', 'ap_hi', 'ap_lo', 'bmi', \n",
    "                     'pulse_pressure', 'health_index', 'cholesterol_gluc_interaction'],\n",
    "        'categorical': ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']\n",
    "    },\n",
    "    'feature_descriptions': {\n",
    "        'gender': 'Gender (1: Female, 2: Male)',\n",
    "        'age_years': 'Age in years',\n",
    "        'weight': 'Weight in kg',\n",
    "        'ap_hi': 'Systolic blood pressure',\n",
    "        'ap_lo': 'Diastolic blood pressure',\n",
    "        'cholesterol': 'Cholesterol level (1: Normal, 2: Above normal, 3: Well above normal)',\n",
    "        'gluc': 'Glucose level (1: Normal, 2: Above normal, 3: Well above normal)',\n",
    "        'smoke': 'Smoking status (0: No, 1: Yes)',\n",
    "        'alco': 'Alcohol intake (0: No, 1: Yes)',\n",
    "        'active': 'Physical activity (0: No, 1: Yes)',\n",
    "        'bmi': 'Body Mass Index (calculated)',\n",
    "        'pulse_pressure': 'Pulse pressure (ap_hi - ap_lo)',\n",
    "        'health_index': 'Health index (active - 0.5*smoke - 0.5*alco)',\n",
    "        'cholesterol_gluc_interaction': 'Interaction between cholesterol and glucose'\n",
    "    },\n",
    "    'feature_ranges': {\n",
    "        'age_years': {'min': int(df['age_years'].min()), 'max': int(df['age_years'].max())},\n",
    "        'weight': {'min': float(df['weight'].min()), 'max': float(df['weight'].max())},\n",
    "        'ap_hi': {'min': float(df['ap_hi'].min()), 'max': float(df['ap_hi'].max())},\n",
    "        'ap_lo': {'min': float(df['ap_lo'].min()), 'max': float(df['ap_lo'].max())},\n",
    "        'bmi': {'min': float(df['bmi'].min()), 'max': float(df['bmi'].max())},\n",
    "        'pulse_pressure': {'min': float(df['pulse_pressure'].min()), 'max': float(df['pulse_pressure'].max())}\n",
    "    },\n",
    "    'engineered_features': {\n",
    "        'bmi': 'weight / (height_m ** 2)',\n",
    "        'pulse_pressure': 'ap_hi - ap_lo',\n",
    "        'health_index': '(active * 1) - (smoke * 0.5) - (alco * 0.5)',\n",
    "        'cholesterol_gluc_interaction': 'cholesterol * gluc'\n",
    "    },\n",
    "    'input_requirements': {\n",
    "        'required_raw_inputs': ['age_days', 'gender', 'height_cm', 'weight', \n",
    "                                'ap_hi', 'ap_lo', 'cholesterol', 'gluc', \n",
    "                                'smoke', 'alco', 'active'],\n",
    "        'preprocessing_steps': [\n",
    "            '1. Convert age from days to years: age_years = (age_days / 365).round()',\n",
    "            '2. Convert height to meters: height_m = height_cm / 100',\n",
    "            '3. Calculate BMI: bmi = weight / (height_m ** 2)',\n",
    "            '4. Calculate pulse_pressure: pulse_pressure = ap_hi - ap_lo',\n",
    "            '5. Calculate health_index: health_index = (active * 1) - (smoke * 0.5) - (alco * 0.5)',\n",
    "            '6. Calculate interaction: cholesterol_gluc_interaction = cholesterol * gluc'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "feature_info_filename = f'feature_info_{timestamp}.pkl'\n",
    "feature_info_path = os.path.join(SAVE_DIR, feature_info_filename)\n",
    "\n",
    "with open(feature_info_path, 'wb') as f:\n",
    "    pickle.dump(feature_info, f)\n",
    "\n",
    "print(f\"âœ“ Feature info saved: {feature_info_filename}\")\n",
    "print(f\"  Total features: {feature_info['n_features']}\")\n",
    "print(f\"  Numerical features: {len(feature_info['feature_types']['numerical'])}\")\n",
    "print(f\"  Categorical features: {len(feature_info['feature_types']['categorical'])}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3. SAVE LABEL ENCODERS (for categorical variables if needed)\n",
    "# ============================================================================\n",
    "print(\"\\n[3] Saving Label Encoders...\")\n",
    "\n",
    "# Since most categorical variables are already numeric, we'll save the mapping\n",
    "label_encoders = {\n",
    "    'gender': {\n",
    "        'mapping': {1: 'Female', 2: 'Male'},\n",
    "        'inverse_mapping': {'Female': 1, 'Male': 2}\n",
    "    },\n",
    "    'cholesterol': {\n",
    "        'mapping': {1: 'Normal', 2: 'Above Normal', 3: 'Well Above Normal'},\n",
    "        'inverse_mapping': {'Normal': 1, 'Above Normal': 2, 'Well Above Normal': 3}\n",
    "    },\n",
    "    'gluc': {\n",
    "        'mapping': {1: 'Normal', 2: 'Above Normal', 3: 'Well Above Normal'},\n",
    "        'inverse_mapping': {'Normal': 1, 'Above Normal': 2, 'Well Above Normal': 3}\n",
    "    },\n",
    "    'smoke': {\n",
    "        'mapping': {0: 'No', 1: 'Yes'},\n",
    "        'inverse_mapping': {'No': 0, 'Yes': 1}\n",
    "    },\n",
    "    'alco': {\n",
    "        'mapping': {0: 'No', 1: 'Yes'},\n",
    "        'inverse_mapping': {'No': 0, 'Yes': 1}\n",
    "    },\n",
    "    'active': {\n",
    "        'mapping': {0: 'No', 1: 'Yes'},\n",
    "        'inverse_mapping': {'No': 0, 'Yes': 1}\n",
    "    },\n",
    "    'target': {\n",
    "        'mapping': {0: 'No Disease', 1: 'Disease'},\n",
    "        'inverse_mapping': {'No Disease': 0, 'Disease': 1}\n",
    "    }\n",
    "}\n",
    "\n",
    "label_encoders_filename = f'label_encoders_{timestamp}.pkl'\n",
    "label_encoders_path = os.path.join(SAVE_DIR, label_encoders_filename)\n",
    "\n",
    "with open(label_encoders_path, 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "\n",
    "print(f\"âœ“ Label encoders saved: {label_encoders_filename}\")\n",
    "print(f\"  Encoded variables: {list(label_encoders.keys())}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. SAVE MODEL METADATA\n",
    "# ============================================================================\n",
    "print(\"\\n[4] Saving Model Metadata...\")\n",
    "\n",
    "# Get Random Forest specific parameters and metrics\n",
    "rf_model = tuned_models['Random Forest']['model']\n",
    "rf_params = tuned_models['Random Forest']['best_params']\n",
    "rf_metrics = {\n",
    "    'accuracy': tuned_models['Random Forest']['accuracy'],\n",
    "    'f1_score': tuned_models['Random Forest']['f1_score'],\n",
    "    'precision': tuned_models['Random Forest']['precision'],\n",
    "    'recall': tuned_models['Random Forest']['recall']\n",
    "}\n",
    "\n",
    "# Get baseline metrics for comparison\n",
    "rf_baseline = {\n",
    "    'accuracy': baseline_results['Random Forest']['accuracy'],\n",
    "    'f1_score': baseline_results['Random Forest']['f1_score'],\n",
    "    'precision': baseline_results['Random Forest']['precision'],\n",
    "    'recall': baseline_results['Random Forest']['recall']\n",
    "}\n",
    "\n",
    "# Collect all performance metrics and model information\n",
    "model_metadata = {\n",
    "    'model_info': {\n",
    "        'model_name': 'Random Forest Classifier',\n",
    "        'model_type': 'RandomForestClassifier',\n",
    "        'library': 'scikit-learn',\n",
    "        'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_version': '1.0',\n",
    "        'best_parameters': rf_params,\n",
    "        'n_estimators': rf_model.n_estimators,\n",
    "        'max_depth': rf_model.max_depth,\n",
    "        'min_samples_split': rf_model.min_samples_split,\n",
    "        'min_samples_leaf': rf_model.min_samples_leaf,\n",
    "        'max_features': rf_model.max_features,\n",
    "        'criterion': rf_model.criterion,\n",
    "        'bootstrap': rf_model.bootstrap\n",
    "    },\n",
    "    'training_info': {\n",
    "        'dataset_size': len(df),\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'train_test_split': 0.75,\n",
    "        'random_state': 42,\n",
    "        'cv_folds': 3,\n",
    "        'class_distribution': {\n",
    "            'train': dict(y_train.value_counts().to_dict()),\n",
    "            'test': dict(y_test.value_counts().to_dict())\n",
    "        }\n",
    "    },\n",
    "    'performance_metrics': {\n",
    "        'test_set': {\n",
    "            'accuracy': float(rf_metrics['accuracy']),\n",
    "            'f1_score': float(rf_metrics['f1_score']),\n",
    "            'precision': float(rf_metrics['precision']),\n",
    "            'recall': float(rf_metrics['recall'])\n",
    "        },\n",
    "        'baseline_comparison': {\n",
    "            'baseline_accuracy': float(rf_baseline['accuracy']),\n",
    "            'baseline_f1_score': float(rf_baseline['f1_score']),\n",
    "            'improvement_accuracy': float(rf_metrics['accuracy'] - rf_baseline['accuracy']),\n",
    "            'improvement_f1_score': float(rf_metrics['f1_score'] - rf_baseline['f1_score'])\n",
    "        }\n",
    "    },\n",
    "    'feature_importance': {\n",
    "        feature_name: float(importance) \n",
    "        for feature_name, importance in zip(X_train.columns, rf_model.feature_importances_)\n",
    "    },\n",
    "    'top_features': {\n",
    "        'names': [X_train.columns[i] for i in rf_model.feature_importances_.argsort()[::-1][:10]],\n",
    "        'importances': [float(rf_model.feature_importances_[i]) \n",
    "                       for i in rf_model.feature_importances_.argsort()[::-1][:10]]\n",
    "    },\n",
    "    'usage_instructions': {\n",
    "        'prediction_example': \"\"\"\n",
    "# Load the model\n",
    "import pickle\n",
    "with open('heart_disease_model_*.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Prepare input data (14 features in this order)\n",
    "input_data = {\n",
    "    'gender': 2,  # Male\n",
    "    'weight': 75,\n",
    "    'ap_hi': 120,\n",
    "    'ap_lo': 80,\n",
    "    'cholesterol': 1,\n",
    "    'gluc': 1,\n",
    "    'smoke': 0,\n",
    "    'alco': 0,\n",
    "    'active': 1,\n",
    "    'age_years': 50,\n",
    "    'bmi': 24.5,\n",
    "    'pulse_pressure': 40,\n",
    "    'health_index': 1.0,\n",
    "    'cholesterol_gluc_interaction': 1\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "import pandas as pd\n",
    "input_df = pd.DataFrame([input_data])\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(input_df)\n",
    "probability = model.predict_proba(input_df)\n",
    "\n",
    "print(f\"Prediction: {prediction[0]}\")  # 0: No Disease, 1: Disease\n",
    "print(f\"Probability: {probability[0]}\")  # [prob_no_disease, prob_disease]\n",
    "        \"\"\",\n",
    "        'required_preprocessing': 'See feature_info.pkl for detailed preprocessing steps'\n",
    "    },\n",
    "    'file_references': {\n",
    "        'model_file': model_filename,\n",
    "        'feature_info_file': feature_info_filename,\n",
    "        'label_encoders_file': label_encoders_filename,\n",
    "        'metadata_file': f'model_metadata_{timestamp}.pkl'\n",
    "    }\n",
    "}\n",
    "\n",
    "model_metadata_filename = f'model_metadata_{timestamp}.pkl'\n",
    "model_metadata_path = os.path.join(SAVE_DIR, model_metadata_filename)\n",
    "\n",
    "with open(model_metadata_path, 'wb') as f:\n",
    "    pickle.dump(model_metadata, f)\n",
    "\n",
    "print(f\"âœ“ Model metadata saved: {model_metadata_filename}\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nâœ… All files saved successfully in '{SAVE_DIR}/' directory:\")\n",
    "print(f\"\\n1. ðŸ“¦ {model_filename}\")\n",
    "print(f\"   - Trained Random Forest model\")\n",
    "print(f\"   - Size: {os.path.getsize(model_path) / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\n2. ðŸ“Š {feature_info_filename}\")\n",
    "print(f\"   - Feature names, types, descriptions\")\n",
    "print(f\"   - Preprocessing requirements\")\n",
    "print(f\"   - Size: {os.path.getsize(feature_info_path) / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\n3. ðŸ·ï¸  {label_encoders_filename}\")\n",
    "print(f\"   - Categorical variable mappings\")\n",
    "print(f\"   - Target variable encoding\")\n",
    "print(f\"   - Size: {os.path.getsize(label_encoders_path) / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\n4. ðŸ“ {model_metadata_filename}\")\n",
    "print(f\"   - Model parameters and performance\")\n",
    "print(f\"   - Training information\")\n",
    "print(f\"   - Usage instructions\")\n",
    "print(f\"   - Size: {os.path.getsize(model_metadata_path) / 1024:.2f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test Set Accuracy:  {model_metadata['performance_metrics']['test_set']['accuracy']:.6f}\")\n",
    "print(f\"Test Set F1 Score:  {model_metadata['performance_metrics']['test_set']['f1_score']:.6f}\")\n",
    "print(f\"Test Set Precision: {model_metadata['performance_metrics']['test_set']['precision']:.6f}\")\n",
    "print(f\"Test Set Recall:    {model_metadata['performance_metrics']['test_set']['recall']:.6f}\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ† Top 5 Most Important Features:\")\n",
    "for i, (name, importance) in enumerate(zip(\n",
    "    model_metadata['top_features']['names'][:5],\n",
    "    model_metadata['top_features']['importances'][:5]\n",
    "), 1):\n",
    "    print(f\"  {i}. {name:30s}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… MODEL SAVING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# BONUS: CREATE A QUICK LOAD FUNCTION\n",
    "# ============================================================================\n",
    "print(\"\\nðŸ’¡ Quick Load Function (save this for later use):\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\"\"\n",
    "def load_heart_disease_model(timestamp):\n",
    "    '''Load the complete model package'''\n",
    "    import pickle\n",
    "    \n",
    "    # Load all components\n",
    "    with open(f'saved_models/heart_disease_model_{timestamp}.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    with open(f'saved_models/feature_info_{timestamp}.pkl', 'rb') as f:\n",
    "        feature_info = pickle.load(f)\n",
    "    \n",
    "    with open(f'saved_models/label_encoders_{timestamp}.pkl', 'rb') as f:\n",
    "        label_encoders = pickle.load(f)\n",
    "    \n",
    "    with open(f'saved_models/model_metadata_{timestamp}.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'feature_info': feature_info,\n",
    "        'label_encoders': label_encoders,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "\n",
    "# Usage:\n",
    "# package = load_heart_disease_model('\"\"\" + timestamp + \"\"\"')\n",
    "# model = package['model']\n",
    "# predictions = model.predict(your_data)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d17d8a5-fc0a-472a-86ad-e34f47e62a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>age_years</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pulse_pressure</th>\n",
       "      <th>health_index</th>\n",
       "      <th>cholesterol_gluc_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9696</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>268386.476526</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44942</th>\n",
       "      <td>1</td>\n",
       "      <td>73.0</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>296158.059150</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54675</th>\n",
       "      <td>1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>192893.792678</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>289590.001524</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39922</th>\n",
       "      <td>1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>135</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>361604.207758</td>\n",
       "      <td>45</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12738</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>283446.712018</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56810</th>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>150</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>276816.608997</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56100</th>\n",
       "      <td>2</td>\n",
       "      <td>68.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>238086.901719</td>\n",
       "      <td>40</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31228</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>150</td>\n",
       "      <td>105</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>377777.777778</td>\n",
       "      <td>45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68351</th>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>235303.663435</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52500 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gender  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  alco  active  \\\n",
       "9696        1    67.0    110     70            1     1      0     0       1   \n",
       "44942       1    73.0     95     60            1     1      0     0       1   \n",
       "54675       1    50.0    100     70            1     3      0     0       1   \n",
       "2344        1    76.0    120     80            1     1      0     0       1   \n",
       "39922       1    88.0    135     90            1     3      0     1       1   \n",
       "...       ...     ...    ...    ...          ...   ...    ...   ...     ...   \n",
       "12738       1    80.0    120     80            1     1      0     0       1   \n",
       "56810       2    80.0    150     90            1     1      0     0       1   \n",
       "56100       2    68.0    120     80            1     3      0     1       1   \n",
       "31228       1    85.0    150    105            3     1      0     0       1   \n",
       "68351       1    58.0    160    100            1     1      0     0       1   \n",
       "\n",
       "       age_years            bmi  pulse_pressure  health_index  \\\n",
       "9696          58  268386.476526              40           1.0   \n",
       "44942         55  296158.059150              35           1.0   \n",
       "54675         54  192893.792678              30           1.0   \n",
       "2344          52  289590.001524              40           1.0   \n",
       "39922         63  361604.207758              45           0.5   \n",
       "...          ...            ...             ...           ...   \n",
       "12738         60  283446.712018              40           1.0   \n",
       "56810         54  276816.608997              60           1.0   \n",
       "56100         60  238086.901719              40           0.5   \n",
       "31228         52  377777.777778              45           1.0   \n",
       "68351         52  235303.663435              60           1.0   \n",
       "\n",
       "       cholesterol_gluc_interaction  \n",
       "9696                              1  \n",
       "44942                             1  \n",
       "54675                             3  \n",
       "2344                              1  \n",
       "39922                             3  \n",
       "...                             ...  \n",
       "12738                             1  \n",
       "56810                             1  \n",
       "56100                             3  \n",
       "31228                             3  \n",
       "68351                             1  \n",
       "\n",
       "[52500 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c88161-88c3-46b0-bafb-5ee80890bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Random Forest - Extensive Hyperparameter Tuning with GridSearchCV\n",
    "# Testing comprehensive parameter combinations for optimal performance\n",
    "# \"\"\"\n",
    "\n",
    "# # ============================================================================\n",
    "# # LIBRARIES IMPORT\n",
    "# # ============================================================================\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pickle\n",
    "# import time\n",
    "# from datetime import datetime\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "# from sklearn.metrics import (accuracy_score, f1_score, recall_score, \n",
    "#                              precision_score, roc_auc_score, confusion_matrix,\n",
    "#                              classification_report, ConfusionMatrixDisplay,\n",
    "#                              make_scorer)\n",
    "\n",
    "# # ============================================================================\n",
    "# # LOAD PREPROCESSED DATA\n",
    "# # ============================================================================\n",
    "# # Assuming X_train, X_test, y_train, y_test are already available\n",
    "# # If not, run the preprocessing code first\n",
    "\n",
    "# print(\"=\"*80)\n",
    "# print(\"RANDOM FOREST - EXTENSIVE HYPERPARAMETER TUNING\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "# print(f\"\\nDataset Info:\")\n",
    "# print(f\"  Training samples: {len(X_train)}\")\n",
    "# print(f\"  Testing samples:  {len(X_test)}\")\n",
    "# print(f\"  Number of features: {X_train.shape[1]}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # BASELINE RANDOM FOREST\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[1] BASELINE RANDOM FOREST (Your Best Parameters So Far)\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Using your best parameters as baseline\n",
    "# baseline_rf = RandomForestClassifier(\n",
    "#     n_estimators=100,\n",
    "#     max_depth=30,\n",
    "#     min_samples_split=10,\n",
    "#     min_samples_leaf=4,\n",
    "#     max_features='log2',\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# print(\"\\nðŸ“‹ Baseline Parameters:\")\n",
    "# print(f\"  n_estimators:      100\")\n",
    "# print(f\"  max_depth:         30\")\n",
    "# print(f\"  min_samples_split: 10\")\n",
    "# print(f\"  min_samples_leaf:  4\")\n",
    "# print(f\"  max_features:      log2\")\n",
    "\n",
    "# print(\"\\nTraining baseline model...\")\n",
    "# start_time = time.time()\n",
    "# baseline_rf.fit(X_train, y_train)\n",
    "# training_time = time.time() - start_time\n",
    "\n",
    "# y_pred_baseline = baseline_rf.predict(X_test)\n",
    "# y_proba_baseline = baseline_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# baseline_metrics = {\n",
    "#     'accuracy': accuracy_score(y_test, y_pred_baseline),\n",
    "#     'f1_score': f1_score(y_test, y_pred_baseline),\n",
    "#     'precision': precision_score(y_test, y_pred_baseline),\n",
    "#     'recall': recall_score(y_test, y_pred_baseline),\n",
    "#     'roc_auc': roc_auc_score(y_test, y_proba_baseline),\n",
    "#     'training_time': training_time\n",
    "# }\n",
    "\n",
    "# print(f\"\\nðŸ“Š Baseline Performance:\")\n",
    "# print(f\"  Accuracy:      {baseline_metrics['accuracy']:.6f}\")\n",
    "# print(f\"  F1 Score:      {baseline_metrics['f1_score']:.6f}\")\n",
    "# print(f\"  Precision:     {baseline_metrics['precision']:.6f}\")\n",
    "# print(f\"  Recall:        {baseline_metrics['recall']:.6f}\")\n",
    "# print(f\"  ROC AUC:       {baseline_metrics['roc_auc']:.6f}\")\n",
    "# print(f\"  Training Time: {baseline_metrics['training_time']:.2f} seconds\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # EXPANDED PARAMETER GRID\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[2] EXPANDED PARAMETER GRID FOR GRIDSEARCHCV\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Comprehensive parameter grid with more options\n",
    "# rf_param_grid_expanded = {\n",
    "#     # Number of trees in the forest\n",
    "#     'n_estimators': [50, 100, 150, 200, 250, 300, 400, 500],\n",
    "    \n",
    "#     # Maximum depth of each tree\n",
    "#     'max_depth': [5, 10, 15, 20, 25, 30, 40, 50, None],\n",
    "    \n",
    "#     # Minimum samples required to split an internal node\n",
    "#     'min_samples_split': [2, 5, 10, 15, 20, 25],\n",
    "    \n",
    "#     # Minimum samples required at a leaf node\n",
    "#     'min_samples_leaf': [1, 2, 4, 6, 8, 10],\n",
    "    \n",
    "#     # Number of features to consider at every split\n",
    "#     'max_features': ['sqrt', 'log2', None, 0.3, 0.5, 0.7],\n",
    "    \n",
    "#     # Bootstrap samples when building trees\n",
    "#     'bootstrap': [True, False],\n",
    "    \n",
    "#     # Criterion to measure split quality\n",
    "#     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    \n",
    "#     # Minimum weighted fraction of samples required at leaf\n",
    "#     'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "    \n",
    "#     # Maximum number of leaf nodes\n",
    "#     'max_leaf_nodes': [None, 10, 20, 50, 100],\n",
    "    \n",
    "#     # Minimum impurity decrease for split\n",
    "#     'min_impurity_decrease': [0.0, 0.01, 0.05, 0.1]\n",
    "# }\n",
    "\n",
    "# print(\"\\nðŸ“‹ Parameter Grid Details:\")\n",
    "# print(f\"  n_estimators: {rf_param_grid_expanded['n_estimators']}\")\n",
    "# print(f\"  max_depth: {rf_param_grid_expanded['max_depth']}\")\n",
    "# print(f\"  min_samples_split: {rf_param_grid_expanded['min_samples_split']}\")\n",
    "# print(f\"  min_samples_leaf: {rf_param_grid_expanded['min_samples_leaf']}\")\n",
    "# print(f\"  max_features: {rf_param_grid_expanded['max_features']}\")\n",
    "# print(f\"  bootstrap: {rf_param_grid_expanded['bootstrap']}\")\n",
    "# print(f\"  criterion: {rf_param_grid_expanded['criterion']}\")\n",
    "# print(f\"  min_weight_fraction_leaf: {rf_param_grid_expanded['min_weight_fraction_leaf']}\")\n",
    "# print(f\"  max_leaf_nodes: {rf_param_grid_expanded['max_leaf_nodes']}\")\n",
    "# print(f\"  min_impurity_decrease: {rf_param_grid_expanded['min_impurity_decrease']}\")\n",
    "\n",
    "# total_combinations = np.prod([len(v) for v in rf_param_grid_expanded.values()])\n",
    "# print(f\"\\nâš ï¸  Total possible combinations: {total_combinations:,}\")\n",
    "# print(f\"    This is computationally expensive. Consider using a subset.\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # PRACTICAL PARAMETER GRID (RECOMMENDED)\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[3] PRACTICAL PARAMETER GRID (RECOMMENDED FOR GRIDSEARCHCV)\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # More practical grid with most important parameters\n",
    "# rf_param_grid_practical = {\n",
    "#     'n_estimators': [100, 200, 300, 400, 500],\n",
    "#     'max_depth': [10, 20, 30, 40, None],\n",
    "#     'min_samples_split': [2, 5, 10, 15],\n",
    "#     'min_samples_leaf': [1, 2, 4, 8],\n",
    "#     'max_features': ['sqrt', 'log2', 0.5],\n",
    "#     'bootstrap': [True, False],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'min_impurity_decrease': [0.0, 0.01]\n",
    "# }\n",
    "\n",
    "# practical_combinations = np.prod([len(v) for v in rf_param_grid_practical.values()])\n",
    "# print(f\"\\nâœ… Practical combinations: {practical_combinations:,}\")\n",
    "# print(f\"   With 3-fold CV: {practical_combinations * 3:,} model fits\")\n",
    "\n",
    "# print(\"\\nðŸ“‹ Practical Grid Details:\")\n",
    "# for param, values in rf_param_grid_practical.items():\n",
    "#     print(f\"  {param}: {values}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # GRIDSEARCHCV - STAGE 1: FAST COARSE SEARCH (Around Your Best Parameters)\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[4] STAGE 1: FAST COARSE SEARCH (Around Your Best Parameters)\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Much smaller, focused search centered around your best parameters\n",
    "# rf_param_grid_coarse = {\n",
    "#     'n_estimators': [100, 150, 200],\n",
    "#     'max_depth': [25, 30, 35],\n",
    "#     'min_samples_split': [8, 10, 12],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'max_features': ['log2', 0.4],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "\n",
    "# print(\"\\nðŸ” Starting Fast Coarse Grid Search...\")\n",
    "# print(f\"   Combinations to test: {np.prod([len(v) for v in rf_param_grid_coarse.values()])}\")\n",
    "# print(f\"   Cross-validation folds: 3\")\n",
    "# print(f\"   Scoring metric: F1 Score\")\n",
    "# print(f\"   Parallel jobs: All available CPUs\")\n",
    "# print(f\"   Estimated time: ~5-10 minutes\")\n",
    "\n",
    "# grid_search_coarse = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "#     param_grid=rf_param_grid_coarse,\n",
    "#     cv=3,  # Reduced from 5 to 3 for speed\n",
    "#     scoring='f1',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1,  # Reduced verbosity\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "# start_time = time.time()\n",
    "# grid_search_coarse.fit(X_train, y_train)\n",
    "# coarse_time = time.time() - start_time\n",
    "\n",
    "# print(f\"\\nâœ… Coarse search completed in {coarse_time/60:.2f} minutes\")\n",
    "# print(f\"\\nðŸ† Best Parameters (Coarse):\")\n",
    "# for param, value in grid_search_coarse.best_params_.items():\n",
    "#     print(f\"  {param}: {value}\")\n",
    "# print(f\"\\nðŸ“Š Best Cross-Validation F1 Score: {grid_search_coarse.best_score_:.6f}\")\n",
    "\n",
    "# # Test on test set\n",
    "# y_pred_coarse = grid_search_coarse.best_estimator_.predict(X_test)\n",
    "# y_proba_coarse = grid_search_coarse.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# coarse_metrics = {\n",
    "#     'accuracy': accuracy_score(y_test, y_pred_coarse),\n",
    "#     'f1_score': f1_score(y_test, y_pred_coarse),\n",
    "#     'precision': precision_score(y_test, y_pred_coarse),\n",
    "#     'recall': recall_score(y_test, y_pred_coarse),\n",
    "#     'roc_auc': roc_auc_score(y_test, y_proba_coarse)\n",
    "# }\n",
    "\n",
    "# print(f\"\\nðŸ“Š Test Set Performance (Coarse):\")\n",
    "# print(f\"  Accuracy:  {coarse_metrics['accuracy']:.6f}\")\n",
    "# print(f\"  F1 Score:  {coarse_metrics['f1_score']:.6f}\")\n",
    "# print(f\"  Precision: {coarse_metrics['precision']:.6f}\")\n",
    "# print(f\"  Recall:    {coarse_metrics['recall']:.6f}\")\n",
    "# print(f\"  ROC AUC:   {coarse_metrics['roc_auc']:.6f}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # GRIDSEARCHCV - STAGE 2: FOCUSED FINE-TUNING\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[5] STAGE 2: FOCUSED FINE-TUNING AROUND BEST PARAMETERS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Build a smaller fine-tuning grid around best parameters\n",
    "# best_params = grid_search_coarse.best_params_\n",
    "\n",
    "# # Create tight fine-tuning ranges\n",
    "# rf_param_grid_fine = {}\n",
    "\n",
    "# # n_estimators: narrow range around best\n",
    "# best_n_est = best_params['n_estimators']\n",
    "# rf_param_grid_fine['n_estimators'] = [\n",
    "#     max(50, best_n_est - 25),\n",
    "#     best_n_est,\n",
    "#     best_n_est + 25\n",
    "# ]\n",
    "\n",
    "# # max_depth: narrow range around best\n",
    "# best_max_depth = best_params['max_depth']\n",
    "# rf_param_grid_fine['max_depth'] = [\n",
    "#     best_max_depth - 3,\n",
    "#     best_max_depth,\n",
    "#     best_max_depth + 3\n",
    "# ]\n",
    "\n",
    "# # min_samples_split: narrow range\n",
    "# best_mss = best_params['min_samples_split']\n",
    "# rf_param_grid_fine['min_samples_split'] = [\n",
    "#     max(2, best_mss - 1),\n",
    "#     best_mss,\n",
    "#     best_mss + 1\n",
    "# ]\n",
    "\n",
    "# # min_samples_leaf: narrow range\n",
    "# best_msl = best_params['min_samples_leaf']\n",
    "# rf_param_grid_fine['min_samples_leaf'] = [\n",
    "#     max(1, best_msl - 1),\n",
    "#     best_msl,\n",
    "#     best_msl + 1\n",
    "# ]\n",
    "\n",
    "# # max_features: keep best + 1 alternative\n",
    "# rf_param_grid_fine['max_features'] = [best_params['max_features'], 0.5]\n",
    "\n",
    "# # criterion: keep best only\n",
    "# rf_param_grid_fine['criterion'] = [best_params['criterion']]\n",
    "\n",
    "# # Additional quick-test parameters\n",
    "# rf_param_grid_fine['bootstrap'] = [True]\n",
    "# rf_param_grid_fine['min_impurity_decrease'] = [0.0, 0.001]\n",
    "\n",
    "# print(f\"\\nðŸ” Starting Focused Fine-Tuning...\")\n",
    "# print(f\"   Combinations to test: {np.prod([len(v) for v in rf_param_grid_fine.values()])}\")\n",
    "# print(f\"   Cross-validation folds: 3\")\n",
    "# print(f\"   Estimated time: ~3-5 minutes\")\n",
    "\n",
    "# grid_search_fine = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "#     param_grid=rf_param_grid_fine,\n",
    "#     cv=3,\n",
    "#     scoring='f1',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1,\n",
    "#     return_train_score=True\n",
    "# )\n",
    "\n",
    "# start_time = time.time()\n",
    "# grid_search_fine.fit(X_train, y_train)\n",
    "# fine_time = time.time() - start_time\n",
    "\n",
    "# print(f\"\\nâœ… Fine-tuning completed in {fine_time/60:.2f} minutes\")\n",
    "# print(f\"\\nðŸ† Best Parameters (Fine-Tuned):\")\n",
    "# for param, value in grid_search_fine.best_params_.items():\n",
    "#     print(f\"  {param}: {value}\")\n",
    "# print(f\"\\nðŸ“Š Best Cross-Validation F1 Score: {grid_search_fine.best_score_:.6f}\")\n",
    "\n",
    "# # Test on test set\n",
    "# y_pred_fine = grid_search_fine.best_estimator_.predict(X_test)\n",
    "# y_proba_fine = grid_search_fine.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# fine_metrics = {\n",
    "#     'accuracy': accuracy_score(y_test, y_pred_fine),\n",
    "#     'f1_score': f1_score(y_test, y_pred_fine),\n",
    "#     'precision': precision_score(y_test, y_pred_fine),\n",
    "#     'recall': recall_score(y_test, y_pred_fine),\n",
    "#     'roc_auc': roc_auc_score(y_test, y_proba_fine)\n",
    "# }\n",
    "\n",
    "# print(f\"\\nðŸ“Š Test Set Performance (Fine-Tuned):\")\n",
    "# print(f\"  Accuracy:  {fine_metrics['accuracy']:.6f}\")\n",
    "# print(f\"  F1 Score:  {fine_metrics['f1_score']:.6f}\")\n",
    "# print(f\"  Precision: {fine_metrics['precision']:.6f}\")\n",
    "# print(f\"  Recall:    {fine_metrics['recall']:.6f}\")\n",
    "# print(f\"  ROC AUC:   {fine_metrics['roc_auc']:.6f}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # PERFORMANCE COMPARISON\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[6] PERFORMANCE COMPARISON - ALL STAGES\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# comparison_df = pd.DataFrame({\n",
    "#     'Stage': ['Baseline', 'Coarse Search', 'Fine-Tuned'],\n",
    "#     'Accuracy': [baseline_metrics['accuracy'], coarse_metrics['accuracy'], fine_metrics['accuracy']],\n",
    "#     'F1 Score': [baseline_metrics['f1_score'], coarse_metrics['f1_score'], fine_metrics['f1_score']],\n",
    "#     'Precision': [baseline_metrics['precision'], coarse_metrics['precision'], fine_metrics['precision']],\n",
    "#     'Recall': [baseline_metrics['recall'], coarse_metrics['recall'], fine_metrics['recall']],\n",
    "#     'ROC AUC': [baseline_metrics['roc_auc'], coarse_metrics['roc_auc'], fine_metrics['roc_auc']]\n",
    "# })\n",
    "\n",
    "# print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# # Calculate improvements\n",
    "# print(f\"\\nðŸ“ˆ Improvement from Baseline to Fine-Tuned:\")\n",
    "# print(f\"  Accuracy:  {(fine_metrics['accuracy'] - baseline_metrics['accuracy'])*100:+.4f}%\")\n",
    "# print(f\"  F1 Score:  {(fine_metrics['f1_score'] - baseline_metrics['f1_score'])*100:+.4f}%\")\n",
    "# print(f\"  Precision: {(fine_metrics['precision'] - baseline_metrics['precision'])*100:+.4f}%\")\n",
    "# print(f\"  Recall:    {(fine_metrics['recall'] - baseline_metrics['recall'])*100:+.4f}%\")\n",
    "# print(f\"  ROC AUC:   {(fine_metrics['roc_auc'] - baseline_metrics['roc_auc'])*100:+.4f}%\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # VISUALIZATIONS\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[7] GENERATING VISUALIZATIONS\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# # Create output directory\n",
    "# import os\n",
    "# VIZ_DIR = 'rf_visualizations'\n",
    "# os.makedirs(VIZ_DIR, exist_ok=True)\n",
    "\n",
    "# # 1. Performance Comparison Bar Plot\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall', 'ROC AUC']\n",
    "# stages = comparison_df['Stage'].values\n",
    "# x = np.arange(len(metrics))\n",
    "# width = 0.25\n",
    "\n",
    "# for ax, metric_subset in [(axes[0], ['Accuracy', 'F1 Score', 'ROC AUC']), \n",
    "#                            (axes[1], ['Precision', 'Recall'])]:\n",
    "#     for idx, stage in enumerate(stages):\n",
    "#         values = [comparison_df[comparison_df['Stage'] == stage][m].values[0] \n",
    "#                  for m in metric_subset]\n",
    "#         positions = np.arange(len(metric_subset)) + (idx - 1) * width\n",
    "#         ax.bar(positions, values, width, label=stage, alpha=0.8)\n",
    "    \n",
    "#     ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "#     ax.set_title(f'Performance Comparison - {\", \".join(metric_subset)}', \n",
    "#                 fontsize=13, fontweight='bold')\n",
    "#     ax.set_xticks(np.arange(len(metric_subset)))\n",
    "#     ax.set_xticklabels(metric_subset, rotation=0)\n",
    "#     ax.legend()\n",
    "#     ax.grid(axis='y', alpha=0.3)\n",
    "#     ax.set_ylim([0.65, 0.95])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{VIZ_DIR}/01_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "# print(\"âœ“ Saved: Performance Comparison\")\n",
    "# plt.close()\n",
    "\n",
    "# # 2. Confusion Matrices Comparison\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# predictions = [y_pred_baseline, y_pred_coarse, y_pred_fine]\n",
    "# titles = ['Baseline', 'Coarse Search', 'Fine-Tuned']\n",
    "# f1_scores = [baseline_metrics['f1_score'], coarse_metrics['f1_score'], fine_metrics['f1_score']]\n",
    "\n",
    "# for idx, (pred, title, f1) in enumerate(zip(predictions, titles, f1_scores)):\n",
    "#     cm = confusion_matrix(y_test, pred)\n",
    "#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Disease', 'Disease'])\n",
    "#     disp.plot(ax=axes[idx], cmap='Blues', values_format='d')\n",
    "#     axes[idx].set_title(f'{title}\\nF1 Score: {f1:.6f}', fontsize=12, fontweight='bold')\n",
    "#     axes[idx].grid(False)\n",
    "\n",
    "# plt.suptitle('Random Forest - Confusion Matrices Comparison', fontsize=15, fontweight='bold')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{VIZ_DIR}/02_confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
    "# print(\"âœ“ Saved: Confusion Matrices\")\n",
    "# plt.close()\n",
    "\n",
    "# # 3. Feature Importance - Fine-Tuned Model\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# importances = grid_search_fine.best_estimator_.feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# plt.barh(range(len(indices)), importances[indices], alpha=0.8, color='steelblue')\n",
    "# plt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])\n",
    "# plt.xlabel('Feature Importance', fontsize=12, fontweight='bold')\n",
    "# plt.title('Random Forest - Feature Importance (Fine-Tuned Model)', \n",
    "#          fontsize=14, fontweight='bold')\n",
    "# plt.grid(axis='x', alpha=0.3)\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{VIZ_DIR}/03_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "# print(\"âœ“ Saved: Feature Importance\")\n",
    "# plt.close()\n",
    "\n",
    "# # 4. GridSearchCV Results Heatmap (Top parameters)\n",
    "# cv_results = pd.DataFrame(grid_search_fine.cv_results_)\n",
    "# top_10 = cv_results.nlargest(10, 'mean_test_score')[\n",
    "#     ['param_n_estimators', 'param_max_depth', 'param_min_samples_split', \n",
    "#      'mean_test_score', 'std_test_score']\n",
    "# ]\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "# top_10_display = top_10.copy()\n",
    "# top_10_display.columns = ['N Estimators', 'Max Depth', 'Min Samples Split', \n",
    "#                           'Mean F1', 'Std F1']\n",
    "# top_10_display = top_10_display.reset_index(drop=True)\n",
    "\n",
    "# # Create text display\n",
    "# cell_text = []\n",
    "# for idx, row in top_10_display.iterrows():\n",
    "#     cell_text.append([\n",
    "#         str(row['N Estimators']),\n",
    "#         str(row['Max Depth']),\n",
    "#         str(row['Min Samples Split']),\n",
    "#         f\"{row['Mean F1']:.6f}\",\n",
    "#         f\"{row['Std F1']:.6f}\"\n",
    "#     ])\n",
    "\n",
    "# table = ax.table(cellText=cell_text, colLabels=top_10_display.columns,\n",
    "#                 cellLoc='center', loc='center',\n",
    "#                 colWidths=[0.15, 0.15, 0.2, 0.15, 0.15])\n",
    "# table.auto_set_font_size(False)\n",
    "# table.set_fontsize(10)\n",
    "# table.scale(1, 2)\n",
    "\n",
    "# # Color the best row\n",
    "# for i in range(len(top_10_display.columns)):\n",
    "#     table[(1, i)].set_facecolor('#90EE90')\n",
    "#     table[(1, i)].set_text_props(weight='bold')\n",
    "\n",
    "# ax.axis('off')\n",
    "# ax.set_title('Top 10 Parameter Combinations (Fine-Tuned GridSearch)', \n",
    "#             fontsize=14, fontweight='bold', pad=20)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{VIZ_DIR}/04_top_parameters.png', dpi=300, bbox_inches='tight')\n",
    "# print(\"âœ“ Saved: Top Parameters Table\")\n",
    "# plt.close()\n",
    "\n",
    "# # 5. Quick Learning Curve - Compare n_estimators\n",
    "# print(\"\\nðŸ“Š Generating quick learning curve...\")\n",
    "# n_estimators_range = [100, 150, 200, 250]  # Reduced range for speed\n",
    "# train_scores = []\n",
    "# test_scores = []\n",
    "\n",
    "# # Use best parameters from fine-tuning, vary only n_estimators\n",
    "# best_params_fine = grid_search_fine.best_params_\n",
    "# for n_est in n_estimators_range:\n",
    "#     rf_temp = RandomForestClassifier(\n",
    "#         n_estimators=n_est,\n",
    "#         max_depth=best_params_fine.get('max_depth', 30),\n",
    "#         min_samples_split=best_params_fine.get('min_samples_split', 10),\n",
    "#         min_samples_leaf=best_params_fine.get('min_samples_leaf', 4),\n",
    "#         max_features=best_params_fine.get('max_features', 'log2'),\n",
    "#         criterion=best_params_fine.get('criterion', 'gini'),\n",
    "#         bootstrap=best_params_fine.get('bootstrap', True),\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "#     rf_temp.fit(X_train, y_train)\n",
    "#     train_scores.append(f1_score(y_train, rf_temp.predict(X_train)))\n",
    "#     test_scores.append(f1_score(y_test, rf_temp.predict(X_test)))\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(n_estimators_range, train_scores, 'o-', label='Training F1', linewidth=2, markersize=8)\n",
    "# plt.plot(n_estimators_range, test_scores, 's-', label='Test F1', linewidth=2, markersize=8)\n",
    "# plt.xlabel('Number of Estimators', fontsize=12, fontweight='bold')\n",
    "# plt.ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
    "# plt.title('Learning Curve - Impact of n_estimators', fontsize=14, fontweight='bold')\n",
    "# plt.legend(fontsize=11)\n",
    "# plt.grid(alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(f'{VIZ_DIR}/05_learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "# print(\"âœ“ Saved: Learning Curve\")\n",
    "# plt.close()\n",
    "\n",
    "# # ============================================================================\n",
    "# # SAVE FINAL MODEL\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"[8] SAVING FINAL MODEL\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# final_model = grid_search_fine.best_estimator_\n",
    "# model_path = 'models_cache/random_forest_final_tuned.pkl'\n",
    "\n",
    "# with open(model_path, 'wb') as f:\n",
    "#     pickle.dump({\n",
    "#         'model': final_model,\n",
    "#         'best_params': grid_search_fine.best_params_,\n",
    "#         'best_score': grid_search_fine.best_score_,\n",
    "#         'test_metrics': fine_metrics,\n",
    "#         'feature_names': list(X_train.columns)\n",
    "#     }, f)\n",
    "\n",
    "# print(f\"âœ… Model saved to: {model_path}\")\n",
    "\n",
    "# # ============================================================================\n",
    "# # FINAL SUMMARY\n",
    "# # ============================================================================\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"FINAL SUMMARY\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# print(\"\\nðŸ† BEST RANDOM FOREST MODEL:\")\n",
    "# print(f\"  Cross-Validation F1: {grid_search_fine.best_score_:.6f}\")\n",
    "# print(f\"  Test Set F1:         {fine_metrics['f1_score']:.6f}\")\n",
    "# print(f\"  Test Set Accuracy:   {fine_metrics['accuracy']:.6f}\")\n",
    "\n",
    "# print(\"\\nðŸ“‹ Optimal Hyperparameters:\")\n",
    "# for param, value in grid_search_fine.best_params_.items():\n",
    "#     print(f\"  {param}: {value}\")\n",
    "\n",
    "# print(f\"\\nâ±ï¸  Total Tuning Time: {(coarse_time + fine_time)/60:.2f} minutes\")\n",
    "# print(f\"  - Coarse Search: {coarse_time/60:.2f} minutes\")\n",
    "# print(f\"  - Fine Tuning:   {fine_time/60:.2f} minutes\")\n",
    "\n",
    "# print(f\"\\nðŸ“ Outputs:\")\n",
    "# print(f\"  Visualizations: {VIZ_DIR}/\")\n",
    "# print(f\"  Model file: {model_path}\")\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"âœ… RANDOM FOREST TUNING COMPLETE!\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "074c8299-b2a5-44ed-bbb4-603de13eb1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr = RandomForestClassifier(\n",
    "#     bootstrap=True,\n",
    "#     criterion=\"entropy\",\n",
    "#     max_depth=25,\n",
    "#     max_features=0.4,\n",
    "#     min_impurity_decrease=0.0,\n",
    "#     min_samples_leaf=4,\n",
    "#     min_samples_split=12,\n",
    "#     n_estimators=100,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df8c57-d3ff-46c9-9421-1d999ff60dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
